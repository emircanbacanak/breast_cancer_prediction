{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9293524,"sourceType":"datasetVersion","datasetId":5626466}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-18T14:32:36.116724Z","iopub.execute_input":"2024-09-18T14:32:36.117125Z","iopub.status.idle":"2024-09-18T14:32:40.488634Z","shell.execute_reply.started":"2024-09-18T14:32:36.117087Z","shell.execute_reply":"2024-09-18T14:32:40.487686Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Öncelikle gerekli kütüphaneleri içe aktarıyoruz. Burada, görüntü işleme için **ImageDataGenerator**, çeşitli makine öğrenme modelleri ve değerlendirme metriklerini kullanacağız. Ayrıca veri görselleştirmeleri için **matplotlib** ve **seaborn** kütüphanelerini kullanarak, sonuçları daha anlaşılır hale getireceğiz.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import AgglomerativeClustering, KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:24.322984Z","iopub.execute_input":"2024-09-19T11:31:24.323540Z","iopub.status.idle":"2024-09-19T11:31:24.331007Z","shell.execute_reply.started":"2024-09-19T11:31:24.323482Z","shell.execute_reply":"2024-09-19T11:31:24.329348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veri setimizi tanımlıyoruz. Eğitim ve test verilerinin dizinlerini belirleyerek, bu verilerin yükleneceği yolları ayarlıyoruz.","metadata":{}},{"cell_type":"code","source":"train_dir = '/kaggle/input/breast-cancer-detection/train'\ntest_dir = '/kaggle/input/breast-cancer-detection/test'","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:27.222399Z","iopub.execute_input":"2024-09-19T11:31:27.222933Z","iopub.status.idle":"2024-09-19T11:31:27.228588Z","shell.execute_reply.started":"2024-09-19T11:31:27.222877Z","shell.execute_reply":"2024-09-19T11:31:27.227251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Görüntülerin boyutunu (64x64) ve **batch_sizei** ayarlıyoruz. Bu adımda, veri artırma kullanmadan sadece görüntüleri normalleştirmek için **ImageDataGenerator** kullanıyoruz. Bu, gözetimsiz modellerde kullanılacak.","metadata":{}},{"cell_type":"code","source":"image_size = (64, 64)\nbatch_size = 32\n\ntrain_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:29.609046Z","iopub.execute_input":"2024-09-19T11:31:29.609531Z","iopub.status.idle":"2024-09-19T11:31:29.617422Z","shell.execute_reply.started":"2024-09-19T11:31:29.609488Z","shell.execute_reply":"2024-09-19T11:31:29.615673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eğitim ve test verilerini yükleyerek, her iki set için birer **generator** oluşturuyoruz. Burada önemli olan **class_mode=None** kullanmak, çünkü gözetimsiz öğrenme yapıyoruz ve etiketler kullanılmıyor.","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode=None,  # Gözetimsiz\n    shuffle=True\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode=None,  # Gözetimsiz\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:31.523710Z","iopub.execute_input":"2024-09-19T11:31:31.524235Z","iopub.status.idle":"2024-09-19T11:31:32.098531Z","shell.execute_reply.started":"2024-09-19T11:31:31.524184Z","shell.execute_reply":"2024-09-19T11:31:32.097406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test verisindeki gerçek etiketleri almak için .**classes** özelliğini kullanıyoruz. Bu özellik, her sınıfa atanan etiketleri döndürüyor.","metadata":{}},{"cell_type":"code","source":"test_labels = test_generator.classes","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:37.154087Z","iopub.execute_input":"2024-09-19T11:31:37.154612Z","iopub.status.idle":"2024-09-19T11:31:37.160836Z","shell.execute_reply.started":"2024-09-19T11:31:37.154561Z","shell.execute_reply":"2024-09-19T11:31:37.159242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veriyi batch'ler halinde işlemek için bir fonksiyon yazıyoruz. Bu sayede bellek kullanımını optimize edebiliriz. **AgglomerativeClustering** algoritması için **fit_predict** kullanıyoruz, diğer modeller için ise **predict** fonksiyonunu çağırıyoruz.\n\n","metadata":{}},{"cell_type":"code","source":"def batch_processing(generator, model, is_agglomerative=False):\n    predictions = []\n    for i, batch in enumerate(generator):\n        if i >= len(generator):\n            break\n        X_batch = batch.reshape(len(batch), -1)\n        X_batch_scaled = scaler.transform(X_batch)\n        \n        if is_agglomerative:\n            preds = model.fit_predict(X_batch_scaled)  # Agglomerative için fit_predict kullanıyoruz\n        else:\n            preds = model.predict(X_batch_scaled)\n        \n        predictions.extend(preds)\n    \n    return np.array(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:38.333122Z","iopub.execute_input":"2024-09-19T11:31:38.333685Z","iopub.status.idle":"2024-09-19T11:31:38.342420Z","shell.execute_reply.started":"2024-09-19T11:31:38.333615Z","shell.execute_reply":"2024-09-19T11:31:38.340729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veriyi ölçeklendirmek için **StandardScaler** kullanıyoruz. Böylece verilerimizin modelleme için daha uygun hale gelmesini sağlıyoruz.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:40.181986Z","iopub.execute_input":"2024-09-19T11:31:40.182511Z","iopub.status.idle":"2024-09-19T11:31:40.188143Z","shell.execute_reply.started":"2024-09-19T11:31:40.182461Z","shell.execute_reply":"2024-09-19T11:31:40.186974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Şimdi gözetimsiz öğrenme modellerimizi tanımlıyoruz. Burada iki farklı model kullanıyoruz: **K-Means** ve **AgglomerativeClustering**. Bu modellerin her ikisini de aynı yapı üzerinde çalıştıracağız.","metadata":{}},{"cell_type":"code","source":"unsupervised_models = {\n    'Hierarchical Clustering': AgglomerativeClustering(n_clusters=2),\n    'K-Means': KMeans(n_clusters=2, random_state=42, n_init=10),\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:42.040438Z","iopub.execute_input":"2024-09-19T11:31:42.041023Z","iopub.status.idle":"2024-09-19T11:31:42.049101Z","shell.execute_reply.started":"2024-09-19T11:31:42.040963Z","shell.execute_reply":"2024-09-19T11:31:42.047194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veriyi batch'ler halinde işleyerek düzleştiriyoruz. Görüntülerin 2D halinden 1D hale getirilmesi ve ardından ölçeklendirilmesi işlemi burada yapılıyor. Bu, verinin modeller tarafından işlenmesi için gerekli.","metadata":{}},{"cell_type":"code","source":"unsupervised_results = {}\nX_train_batches = np.vstack([train_generator[i] for i in range(len(train_generator))])\nX_train_flat = X_train_batches.reshape(len(X_train_batches), -1)\nX_train_flat_scaled = scaler.fit_transform(X_train_flat)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:44.288778Z","iopub.execute_input":"2024-09-19T11:31:44.289285Z","iopub.status.idle":"2024-09-19T11:31:53.498533Z","shell.execute_reply.started":"2024-09-19T11:31:44.289239Z","shell.execute_reply":"2024-09-19T11:31:53.497252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Her iki modelimizi eğitim verisi üzerinde eğitiyoruz ve ardından test verisindeki görüntüler üzerinde tahminler yapıyoruz. **AgglomerativeClustering** için **fit_predict**, diğer model için ise **predict** kullanıyoruz.","metadata":{}},{"cell_type":"code","source":"for model_name, model in unsupervised_models.items():\n    if hasattr(model, 'fit'):\n        model.fit(X_train_flat_scaled)\n\n    is_agglomerative = model_name == 'Hierarchical Clustering'\n    y_pred = batch_processing(test_generator, model, is_agglomerative)\n\n    if np.bincount(y_pred.astype(int))[0] != np.bincount(test_labels)[0]:\n        y_pred = 1 - y_pred  # 0 ve 1'i tersine çeviriyoruz\n\n    precision = precision_score(test_labels, y_pred, zero_division=0)\n    recall = recall_score(test_labels, y_pred, zero_division=0)\n    f1 = f1_score(test_labels, y_pred, zero_division=0)\n    accuracy = accuracy_score(test_labels, y_pred)\n    cm = confusion_matrix(test_labels, y_pred)\n    \n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f\"{model_name} - Confusion Matrix\")\n    plt.ylabel('Gerçek Değerler')\n    plt.xlabel('Tahmin Edilen Değerler')\n    plt.show()\n    \n    unsupervised_results[model_name] = {\n        'Precision': precision,\n        'Recall': recall,\n        'F1 Score': f1,\n        'Accuracy': accuracy\n    }\n\n    print(f\"\\n{model_name} Classification Report:\")\n    print(classification_report(test_labels, y_pred, zero_division=0))","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:31:53.500849Z","iopub.execute_input":"2024-09-19T11:31:53.501353Z","iopub.status.idle":"2024-09-19T11:32:29.479976Z","shell.execute_reply.started":"2024-09-19T11:31:53.501295Z","shell.execute_reply":"2024-09-19T11:32:29.478523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Şimdi gözetimsiz öğrenme modellerimizin sonuçlarını topluyoruz ve her bir modelin doğruluk, hassasiyet, geri çağırma ve F1 skorlarını görüntülüyoruz.","metadata":{}},{"cell_type":"code","source":"print(\"\\nGözetimsiz Modeller Sonuçları:\")\nfor model, result in unsupervised_results.items():\n    print(f\"{model}: {result}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:33:26.245491Z","iopub.execute_input":"2024-09-19T11:33:26.246128Z","iopub.status.idle":"2024-09-19T11:33:26.253716Z","shell.execute_reply.started":"2024-09-19T11:33:26.246068Z","shell.execute_reply":"2024-09-19T11:33:26.252274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Çapraz doğrulama (cross-validation) işlemi için **LogisticRegression** modelini tanımlıyoruz ve verileri 5 katlı çapraz doğrulama ile değerlendiriyoruz. Modelin her bir katmanındaki doğruluk sonuçlarını alıyoruz.","metadata":{}},{"cell_type":"code","source":"logreg_model = LogisticRegression(max_iter=5000)\ny_train = train_generator.classes  \ncv = StratifiedKFold(n_splits=5)\ncv_scores = cross_val_score(logreg_model, X_train_flat_scaled, y_train, cv=cv, scoring='accuracy')\n\nprint(f\"\\nÇapraz Doğrulama Skorları: {cv_scores}\") ","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:33:32.951125Z","iopub.execute_input":"2024-09-19T11:33:32.951694Z","iopub.status.idle":"2024-09-19T11:42:07.940773Z","shell.execute_reply.started":"2024-09-19T11:33:32.951624Z","shell.execute_reply":"2024-09-19T11:42:07.939450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# İlk olarak gerekli kütüphaneleri içe aktarıyoruz. Bu kütüphaneler, veri ön işleme, modelleme ve performans değerlendirmesi için kullanılıyor. Özellikle görüntü işleme ve modelleme için gerekli araçları sağlıyorlar.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:45:36.206878Z","iopub.execute_input":"2024-09-19T11:45:36.207440Z","iopub.status.idle":"2024-09-19T11:45:36.215471Z","shell.execute_reply.started":"2024-09-19T11:45:36.207388Z","shell.execute_reply":"2024-09-19T11:45:36.213860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veri dizinlerini tanımlıyoruz. Bu dizinler eğitim, doğrulama (validation) ve test verileri için kullanılıyor. Her bir dizin, ilgili veri setinin bulunduğu yolu gösteriyor.","metadata":{}},{"cell_type":"code","source":"train_dir = '/kaggle/input/breast-cancer-detection/train'\nvalid_dir = '/kaggle/input/breast-cancer-detection/valid'\ntest_dir = '/kaggle/input/breast-cancer-detection/test'","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:45:38.795126Z","iopub.execute_input":"2024-09-19T11:45:38.795747Z","iopub.status.idle":"2024-09-19T11:45:38.803361Z","shell.execute_reply.started":"2024-09-19T11:45:38.795694Z","shell.execute_reply":"2024-09-19T11:45:38.801719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Görüntülerin boyutlarını (150x150) ve **batch_sizei** (32) ayarlıyoruz. **ImageDataGenerator** kullanarak görüntüleri ölçeklendiriyoruz. Eğitim, doğrulama ve test veri setlerini yüklemek için bu ayarları yapıyoruz.","metadata":{}},{"cell_type":"code","source":"image_size = (150, 150)\nbatch_size = 32\n\ndatagen = ImageDataGenerator(rescale=1.0/255.0)\n\ntrain_generator = datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True\n)\n\nvalid_generator = datagen.flow_from_directory(\n    valid_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=False\n)\n\ntest_generator = datagen.flow_from_directory(\n    test_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:45:41.107773Z","iopub.execute_input":"2024-09-19T11:45:41.108377Z","iopub.status.idle":"2024-09-19T11:45:41.492629Z","shell.execute_reply.started":"2024-09-19T11:45:41.108320Z","shell.execute_reply":"2024-09-19T11:45:41.491410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veri işleme fonksiyonu yazıyoruz. Bu fonksiyon, görüntüleri düzleştirir ve standartlaştırır. Eğitim ve test veri setlerini bu işleme tabi tutarak, modelin girişine uygun hale getiriyoruz.","metadata":{}},{"cell_type":"code","source":"def flatten_and_scale(generator):\n    images, labels = [], []\n    for batch_images, batch_labels in generator:\n        images.append(batch_images)\n        labels.append(batch_labels)\n        if generator.batch_index == generator.samples // generator.batch_size:\n            break\n    all_images = np.concatenate(images, axis=0)\n    all_labels = np.concatenate(labels, axis=0)\n\n    # Görüntüleri düzleştirme\n    all_images_flat = np.reshape(all_images, (len(all_images), -1))\n    \n    # Standartlaştırma (StandardScaler)\n    scaler = StandardScaler()\n    all_images_scaled = scaler.fit_transform(all_images_flat)\n    \n    return all_images_scaled, all_labels","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:46:58.906545Z","iopub.execute_input":"2024-09-19T11:46:58.907823Z","iopub.status.idle":"2024-09-19T11:46:58.915834Z","shell.execute_reply.started":"2024-09-19T11:46:58.907758Z","shell.execute_reply":"2024-09-19T11:46:58.914497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eğitim ve test veri setlerini işliyoruz. Düzleştirme ve standartlaştırma işlemini gerçekleştiriyoruz. Bu, modelin verileri daha verimli bir şekilde işleyebilmesi için gerekli.","metadata":{}},{"cell_type":"code","source":"X_train_flat_scaled, y_train = flatten_and_scale(train_generator)\nX_test_flat_scaled, y_test = flatten_and_scale(test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:47:59.055813Z","iopub.execute_input":"2024-09-19T11:47:59.056414Z","iopub.status.idle":"2024-09-19T11:48:11.918229Z","shell.execute_reply.started":"2024-09-19T11:47:59.056357Z","shell.execute_reply":"2024-09-19T11:48:11.916961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gözetimli öğrenme modellerimizi tanımlıyoruz. Burada, Logistic Regression ve Decision Tree modellerini kullanacağız. Her iki model de sınıflandırma problemi için uygun seçeneklerdir.","metadata":{}},{"cell_type":"code","source":"supervised_models = {\n    'Logistic Regression': LogisticRegression(max_iter=2000, solver='liblinear', class_weight='balanced'),\n    'Decision Tree': DecisionTreeClassifier(class_weight='balanced'),\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:49:27.926994Z","iopub.execute_input":"2024-09-19T11:49:27.927536Z","iopub.status.idle":"2024-09-19T11:49:27.934303Z","shell.execute_reply.started":"2024-09-19T11:49:27.927486Z","shell.execute_reply":"2024-09-19T11:49:27.932722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelleri eğitiyoruz ve test verileri üzerinde performanslarını değerlendiriyoruz. Performans metrikleri olarak hassasiyet, geri çağırma, F1 skoru, doğruluk, ortalama kare hata (MSE) ve ortalama mutlak hata (MAE) kullanıyoruz. Ayrıca karışıklık matrisini görselleştiriyoruz.","metadata":{}},{"cell_type":"code","source":"supervised_results = {}\n\nfor model_name, model in supervised_models.items():\n    model.fit(X_train_flat_scaled, y_train)\n    y_pred = model.predict(X_test_flat_scaled)\n    \n    precision = precision_score(y_test, y_pred, zero_division=0)\n    recall = recall_score(y_test, y_pred, zero_division=0)\n    f1 = f1_score(y_test, y_pred, zero_division=0)\n    accuracy = accuracy_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    mae = mean_absolute_error(y_test, y_pred)\n    \n    # Karışıklık Matrisi\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f\"{model_name} - Confusion Matrix\")\n    plt.ylabel('Gerçek Değerler')\n    plt.xlabel('Tahmin Edilen Değerler')\n    plt.show()\n    \n    supervised_results[model_name] = {\n        'Precision': precision,\n        'Recall': recall,\n        'F1 Score': f1,\n        'Accuracy': accuracy,\n        'Mean Squared Error': mse,\n        'Mean Absolute Error': mae\n    }\n    \n    print(f\"\\n{model_name} Classification Report:\")\n    print(classification_report(y_test, y_pred, zero_division=0))","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:49:30.227519Z","iopub.execute_input":"2024-09-19T11:49:30.228543Z","iopub.status.idle":"2024-09-19T11:57:21.800417Z","shell.execute_reply.started":"2024-09-19T11:49:30.228480Z","shell.execute_reply":"2024-09-19T11:57:21.799148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sonuçları yazdırıyoruz. Her bir modelin performansını ve değerlendirme metriklerini görüntülüyoruz.","metadata":{}},{"cell_type":"code","source":"print(\"\\nGözetimli Modeller Sonuçları:\")\nfor model, result in supervised_results.items():\n    print(f\"{model}: {result}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:57:48.914302Z","iopub.execute_input":"2024-09-19T11:57:48.914905Z","iopub.status.idle":"2024-09-19T11:57:48.920724Z","shell.execute_reply.started":"2024-09-19T11:57:48.914843Z","shell.execute_reply":"2024-09-19T11:57:48.919571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# çapraz doğrulama kullanarak, modelin doğruluk skorlarını değerlendiriyoruz. Çapraz doğrulama skorlarının ortalamasını da hesaplıyoruz.","metadata":{}},{"cell_type":"code","source":"logreg_model = LogisticRegression(max_iter=2000, solver='liblinear', class_weight='balanced')\ncv = StratifiedKFold(n_splits=3)\ncv_scores = cross_val_score(logreg_model, X_train_flat_scaled, y_train, cv=cv, scoring='accuracy')\nprint(f\"Ortalama Çapraz Doğrulama Skoru: {cv_scores.mean()}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T11:57:53.603033Z","iopub.execute_input":"2024-09-19T11:57:53.604042Z","iopub.status.idle":"2024-09-19T12:07:31.001185Z","shell.execute_reply.started":"2024-09-19T11:57:53.603981Z","shell.execute_reply":"2024-09-19T12:07:30.997477Z"},"trusted":true},"execution_count":null,"outputs":[]}]}